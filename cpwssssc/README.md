# 裁判文书事实生成
## 任务介绍
该赛道由清华大学互联网司法研究院承办。

裁判文书是法院审理案件后撰写的正式法律文书，其内容包括案件的基本情况、法院的审理过程、法律依据、裁判结果等。在裁判文书中，审理事实查明部分至关重要，它详细记录了案件的事实情况，是法院做出公正裁判的基础。审理事实查明不仅要准确还要详尽，以确保所有相关事实都得到了充分的认定和合理的法律解释。

本任务是对提供的起诉状、答辩状和涉及的所有证据进行整理，认定案件中的事实并生成文书“本院查明”部分，包括时间、地点、参与人员、发生行为的顺序、影响等，确保事件的描述具有连贯性和逻辑性。

## 数据集介绍

本任务技术评测提供的训练集、测试集均取自公开的高质量判决书。

每份数据包括起诉状、答辩状和证据列表三部分。

起诉状：原告对被告提起诉讼的书面请求，描述案件背景、争议焦点及请求法院支持的事项。

答辩状：被告对起诉状的回应，陈述其对原告主张的事实和法律的观点，提出抗辩理由。

证据材料：支持原告和被告主张的证据清单，包括但不限于书证、物证、证人证言等。这些证据旨在证明或反驳起诉状和答辩状中提到的具体事实。证据材料可以对起诉状和答辩状中存在争议的事实描述进行认定。

数据格式：
| 字段名       | 数据类型 | 描述               |
|--------------|----------|--------------------|
| id           | int      | 数据库行号         |
| prosecution  | str      | 指控方的起诉文件   |
| defense      | str      | 指控方的答辩文件   |
| evidence     | dict     | 指控方的证据列表   |

起诉状和答辩状中存在描述可能冲突的事实，参赛者需根据证据逐一核实并确认正确的事实，最终生成一个event列别。参赛者需将所有查明的事实根据逻辑整合起来，生成裁判文书的审理事实段落。


## 评价方式

本次评价分为三部分，分别为查明事实准确度，语义相似度和逻辑通顺度。

事实查明准确度： 查明事实准确度指的是能否根据证据查明起诉状和答辩状中提到的具体事实。我们将逐条对比参赛者提交的event列表和参考答案。每条event采用ROUGE-L评价，最终该部分分数为所有查明事实ROUGE-L的平均分数。

语义相似度：语义相似度衡量的是大模型生成的审理事实段落与真实段落在语义上的一致性，以及语言是否规范、专业。该指标通过BERTScore进行计算。

要件完整性和逻辑性：要件完整性和逻辑性指的审理事实段落是否覆盖了所有重要的事实和要素，描述的案件事实是否具备清晰、连贯的内在逻辑，各事实之间的因果关系是否合理。要件完整性和逻辑性将通过大模型进行评估。

最终成绩根据上述分数加权得到。

## 结果提交形式
提交结果统一命名为`prediction.json`。提交格式参考`prediction.json`，其中每一行为一个字典，对应一个测试样例的答案。

| 字段名 | 数据类型 | 描述                                            |
|--------|----------|-------------------------------------------------|
| id     | int      | 数据库行号                                      |
| event  | dict     | 模型生成的全部事件列表，与证据列表长度一致       |
| fact   | str      | 模型生成的本阶段理事实段落                       |

## 基线系统
`baseline.py`中提供了一个基于`chatglm4`的代码实现，输入格式参考`test_data.json`，输出格式参考`prediction.json`

**基准算法性能：** 
```json
{
    "rouge-l": 0.3838,
    "BertScore": 0.7244,
    "llm_score": 0.4571
}
```
最终 `rouge-l * 0.4 + BertScore * 0.4 + llm_score * 0.2 = 0.534713696`，（超过此分数的队伍进入复赛阶段）

## 封测结果提交形式
对【裁判文书事实生成】评测而言，采用了“服务-请求”方案进行评估。参赛者需要在本地搭建推理服务，之后评估方会通过“访问服务”的方式获取推理结果。参赛者所提供的推理服务须符合以下接口规范要求。
- 参赛者需要提供一个API的URL或域名，以便我们能够访问服务。例如：https://api.example.com/model.
- HTTP方法： API应当支持POST请求方法。
- 请求参数： API应接受一个JSON请求体，示例输入如下：
```json
{
    "id": 0,
    "title": "",
    "fact": "",
    "prosecution": "",
    "defense": "",
    "evidence": {
        "evidence1": "evidence_content1",
        "evidence2": "evidence_content2"
        ..., //所有证据键值列表
        "evidencen": "evidence_contentn"
    }
}
```
- 响应格式： API应当返回一个JSON响应，示例输出如下：
```json
{
    "id": 0,
    "fact": "fact_content1", 
    "event": {
            "evidence1": "event1", 
            "evidence2": "event2",
            ..., //所有证据键值列表
            "evidencen": "eventn"
    }
}
```

- 状态码： 正常情况下，请使用HTTP状态码200表示成功响应
调用代码示例:
```python
import requests
api_url = "https://api.example.com/model"

input_data = {
    "id": 0,
    "title": "",
    "fact": "",
    "prosecution": "",
    "defense": "",
    "evidence": {
        "evidence1": "evidence_content1",
        "evidence2": "evidence_content2"
        ..., # 所有证据键值列表
        "evidencen": "evidence_contentn"
    }
}

response = requests.post(api_url, json=input_data)

result = response.json()
print("模型处理结果:", result)
```

请在（11月16日 00:00 - 11月22日 24:00）准备并测试您的API，我们将在11月23日开始正式测试并得到最终分数。

请确保测试期间您的具备稳定性和可靠性，以便在测试时能够正常访问和使用。

## 封测正式测试说明
- 封测具体提交形式：选手向平台提交一个json文件，内容形如：
```json
{'api_key': 'xxxxxxx'}
```
以'api_key'为键，值为api的具体地址，要求可以顺利通过以下代码访问获取指定格式的返回值：
```
import requests
response = requests.post(api_key, json=data)
result = response.json()
```
- 封测提交时间：11月24日 00:00 - 11月30日 24:00
- 封测将不公开封测数据集及评测日志，若api测试出现问题，请联系比赛负责人处理
- 分数构成：复赛 30% 封测 70%

## 赛程赛制
- 9月13日至11月01日，初赛阶段。
- 10月18日至11月15日，复赛阶段。
- 11月16日至11月30日，封测阶段。

1. 初赛阶段：开启本任务比赛报名，提供小规模数据集，用于编写模型进行训练和测试，选手需在小规模数据上表现超过官方baseline，才能进入复赛。
2. 复赛阶段：开放第二阶段测试。对于高于任务预设基准算法成绩的队伍，我们将提供全量数据并开放第二阶段的测试提交。
3. 封测阶段：封闭评测。第二阶段结束时，所有参赛者需要提交最终模型或调用接口，并在封闭的新测试集上进行测试。